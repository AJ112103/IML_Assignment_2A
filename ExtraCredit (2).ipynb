{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fds-FJr0cHl0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import numpy as np, random\n",
        "\n",
        "seed = 2025\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = T.Compose([\n",
        "    T.RandomCrop(32, padding=4),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914,0.4822,0.4465), (0.2023,0.1994,0.2010))\n",
        "])\n",
        "test_transforms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914,0.4822,0.4465), (0.2023,0.1994,0.2010))\n",
        "])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,            # ← change here\n",
        "    transform=train_transforms\n",
        ")\n",
        "val_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,            # ← and here\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=128, shuffle=True, num_workers=2, pin_memory=True\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_data, batch_size=128, shuffle=False, num_workers=2, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sGcids3czou",
        "outputId": "c9e28b83-16db-4140-afd7-5b60d036e024"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvUnit(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class CompactCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            ConvUnit(3,   64),   # 32→16\n",
        "            ConvUnit(64, 128),   # 16→ 8\n",
        "            ConvUnit(128,256)    #  8→ 4\n",
        "        )\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier  = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.global_pool(x).view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "model = CompactCNN().to(device)"
      ],
      "metadata": {
        "id": "Hf7rtMGJc3ez"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn      = nn.CrossEntropyLoss()\n",
        "opt          = optim.AdamW(model.parameters(), lr=0.002, weight_decay=5e-4)\n",
        "lr_schedule  = CosineAnnealingLR(opt, T_max=30)\n",
        "\n",
        "epochs = 30\n",
        "train_acc_list, val_acc_list = [], []"
      ],
      "metadata": {
        "id": "-1KrH3RBc8cw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(1, epochs+1):\n",
        "\n",
        "    model.train()\n",
        "    correct = total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        opt.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss    = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "    train_acc = 100 * correct / total\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            preds = model(inputs).argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "    val_acc = 100 * correct / total\n",
        "    val_acc_list.append(val_acc)\n",
        "\n",
        "    lr_schedule.step()\n",
        "    print(f\"Epoch {ep:2d}/{epochs} | \"\n",
        "          f\"Train {train_acc:5.2f}% | Test {val_acc:5.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaF2ZLjTc_SB",
        "outputId": "0834aec7-eb80-4613-8ee2-2eedf78581d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/30 | Train 83.41% | Test 77.41%\n",
            "Epoch  2/30 | Train 84.90% | Test 82.18%\n",
            "Epoch  3/30 | Train 86.74% | Test 82.81%\n",
            "Epoch  4/30 | Train 87.73% | Test 84.57%\n",
            "Epoch  5/30 | Train 88.98% | Test 84.35%\n",
            "Epoch  6/30 | Train 89.68% | Test 85.45%\n",
            "Epoch  7/30 | Train 90.65% | Test 86.18%\n",
            "Epoch  8/30 | Train 91.57% | Test 88.13%\n",
            "Epoch  9/30 | Train 92.28% | Test 87.36%\n",
            "Epoch 10/30 | Train 92.98% | Test 84.80%\n",
            "Epoch 11/30 | Train 93.79% | Test 88.78%\n",
            "Epoch 12/30 | Train 94.22% | Test 88.97%\n",
            "Epoch 13/30 | Train 94.88% | Test 88.27%\n",
            "Epoch 14/30 | Train 95.49% | Test 89.03%\n",
            "Epoch 15/30 | Train 96.11% | Test 89.57%\n",
            "Epoch 16/30 | Train 96.26% | Test 89.52%\n",
            "Epoch 17/30 | Train 97.02% | Test 90.05%\n",
            "Epoch 18/30 | Train 97.49% | Test 90.10%\n",
            "Epoch 19/30 | Train 97.56% | Test 90.24%\n",
            "Epoch 20/30 | Train 97.96% | Test 90.57%\n",
            "Epoch 21/30 | Train 98.16% | Test 90.67%\n",
            "Epoch 22/30 | Train 98.42% | Test 90.58%\n",
            "Epoch 23/30 | Train 98.53% | Test 90.80%\n",
            "Epoch 24/30 | Train 98.65% | Test 90.84%\n",
            "Epoch 25/30 | Train 98.70% | Test 90.79%\n",
            "Epoch 26/30 | Train 98.76% | Test 90.85%\n",
            "Epoch 27/30 | Train 98.67% | Test 90.84%\n",
            "Epoch 28/30 | Train 98.72% | Test 90.85%\n",
            "Epoch 29/30 | Train 98.69% | Test 90.75%\n",
            "Epoch 30/30 | Train 98.68% | Test 90.79%\n"
          ]
        }
      ]
    }
  ]
}